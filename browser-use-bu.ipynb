{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lukas notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1739345978772,
     "user": {
      "displayName": "Lukas F",
      "userId": "07341902451649282007"
     },
     "user_tz": 600
    },
    "id": "umuiigDPAqWq",
    "outputId": "d244b72b-b824-448a-963f-69eb82735f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/dev/browser-use\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739151683199,
     "user": {
      "displayName": "Lukas F",
      "userId": "07341902451649282007"
     },
     "user_tz": 600
    },
    "id": "UefuTU8HAr9T",
    "outputId": "27aec969-2fab-4600-8396-c2a8989293ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/dev\n",
      "/Users/lukasfiller/dev/browser-use\n"
     ]
    }
   ],
   "source": [
    "%cd dev\n",
    "%cd browser-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739127208584,
     "user": {
      "displayName": "Lukas F",
      "userId": "07341902451649282007"
     },
     "user_tz": 600
    },
    "id": "TSNTpcKFms4L",
    "outputId": "eefe725a-8b93-4cac-eb76-9db6fb96b786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/dev/browser-use\n"
     ]
    }
   ],
   "source": [
    "#optional\n",
    "\n",
    "!git clone https://github.com/browser-use/browser-use\n",
    "%cd browser-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1739150934419,
     "user": {
      "displayName": "Lukas F",
      "userId": "07341902451649282007"
     },
     "user_tz": 600
    },
    "id": "WxnFfAZvkMoM",
    "outputId": "233b8325-8936-4b19-ecda-1b157c39bd35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: uv\r\n"
     ]
    }
   ],
   "source": [
    "#creates env\n",
    "!uv venv --python 3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hDBmdUhkehq"
   },
   "outputs": [],
   "source": [
    "#reactivates the env\n",
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3952,
     "status": "ok",
     "timestamp": 1739345991053,
     "user": {
      "displayName": "Lukas F",
      "userId": "07341902451649282007"
     },
     "user_tz": 600
    },
    "id": "y8DLzBPxkhlN",
    "outputId": "5d656f8a-5059-44ee-fb2f-1cc8fbef24a9"
   },
   "outputs": [],
   "source": [
    "#run in cli activated .venv as\n",
    "#pip install -U browser-use\n",
    "\n",
    "#or here...run this in the conda env\n",
    "!uv pip install -U browser-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szc-Xq64P2wS"
   },
   "outputs": [],
   "source": [
    "!pip install -U browser-use\n",
    "!pip install -U browser-use[memory]\n",
    "!pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1739346012515,
     "user": {
      "displayName": "Lukas F",
      "userId": "07341902451649282007"
     },
     "user_tz": 600
    },
    "id": "Ec64aqBUlRhU",
    "outputId": "d3c8f4bb-064e-486f-d3d8-7c8de4f924cf"
   },
   "outputs": [],
   "source": [
    "!pip install -U playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ES_fuhBMkjv3"
   },
   "outputs": [],
   "source": [
    "!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This import is required only for jupyter notebooks, since they have their own eventloop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sim1FyeAQidG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#needed to run locally\n",
    "!pip install python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END STANDARD STARTUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] üß† Starting an agent with main_model=qwen3:14b +vision, planner_model=None, extraction_model=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if key in self.model_fields:\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields[key].default is not None\n"
     ]
    }
   ],
   "source": [
    "#ollama building block only\n",
    "#works but still needs to be called\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from browser_use import Agent\n",
    "from pydantic import SecretStr\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "llm=ChatOllama(model=\"qwen3:14b\", num_ctx=32000)\n",
    "\n",
    "# Create agent with the model\n",
    "# Create agent with the model\n",
    "agent = Agent(\n",
    "    task='''research how the digital china program is seeking to advance china\n",
    "    AI capabilities. Use only info found at https://digitalchinawinsthefuture.com/''',\n",
    "    llm=llm,\n",
    "    page_extraction_llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] üß† Starting an agent with main_model=qwen3:14b +vision, planner_model=None, extraction_model=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if key in self.model_fields:\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields[key].default is not None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] üöÄ Starting task: Compare the price of gpt-4o and DeepSeek-V3\n",
      "INFO     [agent] üìç Step 1\n",
      "AppKit is not available. Make sure you are running this on macOS with pyobjc installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if key in self.model_fields:\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields[key].default is not None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] ü§∑ Eval: Unknown - This is the first step, no previous actions have been taken yet.\n",
      "INFO     [agent] üß† Memory: Starting the task to compare the price of gpt-4o and DeepSeek-V3. Current step: 1/100.\n",
      "INFO     [agent] üéØ Next goal: Need to navigate to a website or source that provides pricing information for gpt-4o and DeepSeek-V3.\n",
      "INFO     [agent] üõ†Ô∏è  Action 1/1: {\"go_to_url\":{\"url\":\"https://www.google.com\"}}\n",
      "INFO     [controller] üîó  Navigated to https://www.google.com\n",
      "INFO     [agent] üìç Step 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if key in self.model_fields:\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields[key].default is not None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] üëç Eval: Success - Successfully navigated to Google's homepage. Now, the next step is to perform a search for information on the pricing of gpt-4o and DeepSeek-V3.\n",
      "INFO     [agent] üß† Memory: Step 2/100. Navigated to Google's homepage. Need to search for pricing information on gpt-4o and DeepSeek-V3.\n",
      "INFO     [agent] üéØ Next goal: Use the search bar to input keywords related to the pricing comparison of gpt-4o and DeepSeek-V3.\n",
      "INFO     [agent] üõ†Ô∏è  Action 1/1: {\"input_text\":{\"index\":8,\"text\":\"price comparison gpt-4o DeepSeek-V3\"}}\n",
      "INFO     [controller] ‚å®Ô∏è  Input price comparison gpt-4o DeepSeek-V3 into index 8\n",
      "INFO     [agent] üìç Step 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1' coro=<Agent._verify_llm_connection() done, defined at /Users/lukasfiller/dev/browser-use/browser_use/agent/service.py:1177> exception=Exception('LLM API connection test failed: model \"qwen3\" not found, try pulling it first (status code: 404)')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lukasfiller/dev/browser-use/browser_use/agent/service.py\", line 1201, in _verify_llm_connection\n",
      "    response = await self.llm.ainvoke([HumanMessage(content=test_prompt)])\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 392, in ainvoke\n",
      "    llm_result = await self.agenerate_prompt(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 958, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 916, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1084, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/langchain_ollama/chat_models.py\", line 847, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/langchain_ollama/chat_models.py\", line 677, in _achat_stream_with_aggregation\n",
      "    async for chunk in self._aiterate_over_stream(messages, stop, **kwargs):\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/langchain_ollama/chat_models.py\", line 792, in _aiterate_over_stream\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/langchain_ollama/chat_models.py\", line 625, in _acreate_chat_stream\n",
      "    async for part in await self._async_client.chat(**chat_params):\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_client.py\", line 672, in inner\n",
      "    raise ResponseError(e.response.text, e.response.status_code) from None\n",
      "ollama._types.ResponseError: model \"qwen3\" not found, try pulling it first (status code: 404)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/lukasfiller/dev/browser-use/browser_use/agent/service.py\", line 1223, in _verify_llm_connection\n",
      "    raise Exception(f'LLM API connection test failed: {e}') from e\n",
      "Exception: LLM API connection test failed: model \"qwen3\" not found, try pulling it first (status code: 404)\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if key in self.model_fields:\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields[key].default is not None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] üëç Eval: Success - The search query 'price comparison gpt-4o DeepSeek-V3' was successfully inputted into the search bar (index 8). The search suggestions (indices 11-13) are related to the query, indicating that the input was recognized and processed by Google.\n",
      "INFO     [agent] üß† Memory: Step 3/100. Successfully input the search query. Now need to perform the search to get results comparing the prices of gpt-4o and DeepSeek-V3.\n",
      "INFO     [agent] üéØ Next goal: Execute the search by pressing the Enter key or clicking the search button to retrieve relevant information.\n",
      "INFO     [agent] üõ†Ô∏è  Action 1/1: {\"click_element_by_index\":{\"index\":8}}\n",
      "INFO     [controller] üñ±Ô∏è  Clicked button with index 8: \n",
      "INFO     [agent] üìç Step 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if key in self.model_fields:\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields[key].default is not None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] üëç Eval: Success - The search query was executed successfully, and the search results page has been reached. The current page is the Google search results page for 'price comparison gpt-4o DeepSeek-V3'. The interactive elements include the search results, which may contain relevant information on the pricing of gpt-4o and DeepSeek-V3. The elements [11], [12], [13], [14], [15], and [16] are related to the search query and may be useful for further navigation or extraction of information.\n",
      "INFO     [agent] üß† Memory: Step 4/100. Successfully executed the search query for 'price comparison gpt-4o DeepSeek-V3'. Now need to analyze the search results to find relevant information on the pricing of gpt-4o and DeepSeek-V3.\n",
      "INFO     [agent] üéØ Next goal: Analyze the search results to identify the most relevant sources or links that provide pricing information for gpt-4o and DeepSeek-V3. If no relevant information is found, consider alternative strategies such as refining the search query or exploring other websites.\n",
      "INFO     [agent] üõ†Ô∏è  Action 1/1: {\"extract_content\":{\"goal\":\"Identify links related to pricing information for gpt-4o and DeepSeek-V3 from the search results.\",\"should_strip_link_urls\":false}}\n",
      "INFO     [agent] üìç Step 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if key in self.model_fields:\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields[key].default is not None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] ‚ö† Eval: Failed - The search results page for 'price comparison gpt-4o DeepSeek-V3' was not reached. The current page is still the Google homepage, and no search results are visible. This suggests that the search query was not executed successfully or that the search results are not displayed on the current page.\n",
      "INFO     [agent] üß† Memory: Step 5/100. Attempted to execute the search query for 'price comparison gpt-4o DeepSeek-V3', but the search results page was not reached. The current page is still the Google homepage, and no search results are visible. Need to investigate why the search did not proceed as expected.\n",
      "INFO     [agent] üéØ Next goal: Check if the search was executed correctly by verifying if the search results are displayed. If not, try executing the search again or consider alternative strategies for retrieving the required information.\n",
      "INFO     [agent] üõ†Ô∏è  Action 1/1: {\"click_element_by_index\":{\"index\":15}}\n",
      "INFO     [controller] üñ±Ô∏è  Clicked button with index 15: \n",
      "INFO     [agent] üìç Step 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if key in self.model_fields:\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields[key].default is not None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] üëç Eval: Success - The search results page for 'price comparison gpt-4o DeepSeek-V3' was successfully reached. The current page contains relevant information on the pricing of gpt-4o and DeepSeek-V3, including featured snippets and search results from various sources. The interactive elements include links to articles and blog posts that compare the pricing of these models, such as 'DeepSeek V3 vs. OpenAI's GPT-4o: Which AI Model is Better?' and 'DeepSeek V3 vs GPT-4o: Which is Better? - Analytics Vidhya'. These elements can be used to extract detailed pricing information for both models.\n",
      "INFO     [agent] üß† Memory: Step 6/100. Successfully reached the Google search results page for 'price comparison gpt-4o DeepSeek-V3'. The page contains featured snippets and search results that provide pricing information for gpt-4o and DeepSeek-V3. Need to extract the pricing details from these sources.\n",
      "INFO     [agent] üéØ Next goal: Extract the pricing information for gpt-4o and DeepSeek-V3 from the featured snippets and search results on the current page.\n",
      "INFO     [agent] üõ†Ô∏è  Action 1/1: {\"extract_content\":{\"goal\":\"Extract the pricing details for gpt-4o and DeepSeek-V3 from the featured snippets and search results.\",\"should_strip_link_urls\":false}}\n",
      "INFO     [agent] üìç Step 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if key in self.model_fields:\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields[key].default is not None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] üëç Eval: Success - The search results page for 'price comparison gpt-4o DeepSeek-V3' was successfully reached. The current page contains relevant information on the pricing of gpt-4o and DeepSeek-V3, including featured snippets and search results from various sources. The interactive elements include links to articles and blog posts that compare the pricing of these models, such as 'DeepSeek V3 vs. OpenAI's GPT-4o: Which AI Model is Better?' and 'DeepSeek V3 vs GPT-4o: Which is Better? - Analytics Vidhya'. These elements can be used to extract detailed pricing information for both models.\n",
      "INFO     [agent] üß† Memory: Step 7/100. Successfully reached the Google search results page for 'price comparison gpt-4o DeepSeek-V3'. The page contains featured snippets and search results that provide pricing information for gpt-4o and DeepSeek-V3. Need to extract the pricing details from these sources.\n",
      "INFO     [agent] üéØ Next goal: Extract the pricing information for gpt-4o and DeepSeek-V3 from the featured snippets and search results on the current page.\n",
      "INFO     [agent] üõ†Ô∏è  Action 1/1: {\"extract_content\":{\"goal\":\"Extract the pricing details for gpt-4o and DeepSeek-V3 from the featured snippets and search results.\",\"should_strip_link_urls\":false}}\n",
      "INFO     [agent] üìç Step 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:81: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  if key in self.model_fields:\n",
      "/Users/lukasfiller/miniforge3/envs/browser-use/lib/python3.11/site-packages/ollama/_types.py:82: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields[key].default is not None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [agent] üëç Eval: Success - The featured snippet provides pricing details for both GPT-4o and DeepSeek-V3. GPT-4o charges $1.25 per million input cache hit tokens, $2.50 per million input cache miss tokens, and $10 per million output tokens. DeepSeek-V3 charges $0.07 per million input cache hit tokens, $0.27 per million input cache miss tokens, and $1.10 per million output tokens. This information directly addresses the task of comparing their prices.\n",
      "INFO     [agent] üß† Memory: Step 8/100. Extracted pricing information from the featured snippet on Google's search results page. GPT-4o's pricing is $1.25 per million input cache hit tokens, $2.50 per million input cache miss tokens, and $10 per million output tokens. DeepSeek-V3's pricing is $0.07 per million input cache hit tokens, $0.27 per million input cache miss tokens, and $1.10 per million output tokens. The task is now complete as the pricing comparison has been successfully obtained.\n",
      "INFO     [agent] üéØ Next goal: The task is complete. Use the 'done' action to finalize the comparison of prices between GPT-4o and DeepSeek-V3.\n",
      "INFO     [agent] üõ†Ô∏è  Action 1/1: {\"done\":{\"text\":\"The price comparison between GPT-4o and DeepSeek-V3 is as follows: GPT-4o charges $1.25 per million input cache hit tokens, $2.50 per million input cache miss tokens, and $10 per million output tokens. DeepSeek-V3 charges $0.07 per million input cache hit tokens, $0.27 per million input cache miss tokens, and $1.10 per million output tokens. This makes DeepSeek-V3 significantly more cost-effective compared to GPT-4o.\",\"success\":true}}\n",
      "INFO     [agent] üìÑ Result: The price comparison between GPT-4o and DeepSeek-V3 is as follows: GPT-4o charges $1.25 per million input cache hit tokens, $2.50 per million input cache miss tokens, and $10 per million output tokens. DeepSeek-V3 charges $0.07 per million input cache hit tokens, $0.27 per million input cache miss tokens, and $1.10 per million output tokens. This makes DeepSeek-V3 significantly more cost-effective compared to GPT-4o.\n",
      "INFO     [agent] ‚úÖ Task completed\n",
      "INFO     [agent] ‚úÖ Successfully\n",
      "INFO     [agent] üìù Total input tokens used (approximate): 23053\n",
      "AgentHistoryList(all_results=[ActionResult(is_done=False, success=None, extracted_content='üîó  Navigated to https://www.google.com', error=None, include_in_memory=True), ActionResult(is_done=False, success=None, extracted_content='‚å®Ô∏è  Input price comparison gpt-4o DeepSeek-V3 into index 8', error=None, include_in_memory=True), ActionResult(is_done=False, success=None, extracted_content='üñ±Ô∏è  Clicked button with index 8: ', error=None, include_in_memory=True), ActionResult(is_done=False, success=None, extracted_content='üñ±Ô∏è  Clicked button with index 15: ', error=None, include_in_memory=True), ActionResult(is_done=True, success=True, extracted_content='The price comparison between GPT-4o and DeepSeek-V3 is as follows: GPT-4o charges $1.25 per million input cache hit tokens, $2.50 per million input cache miss tokens, and $10 per million output tokens. DeepSeek-V3 charges $0.07 per million input cache hit tokens, $0.27 per million input cache miss tokens, and $1.10 per million output tokens. This makes DeepSeek-V3 significantly more cost-effective compared to GPT-4o.', error=None, include_in_memory=False)], all_model_outputs=[{'go_to_url': {'url': 'https://www.google.com'}, 'interacted_element': None}, {'input_text': {'index': 8, 'text': 'price comparison gpt-4o DeepSeek-V3'}, 'interacted_element': DOMHistoryElement(tag_name='textarea', xpath='html/body/div/div[3]/form/div/div/div/div/div[2]/textarea', highlight_index=8, entire_parent_branch_path=['div', 'div', 'form', 'div', 'div', 'div', 'div', 'div', 'textarea'], attributes={'class': 'gLFyf', 'aria-controls': 'Alh6id', 'aria-owns': 'Alh6id', 'autofocus': '', 'title': 'Search', 'value': '', 'aria-label': 'Search', 'placeholder': '', 'aria-autocomplete': 'both', 'aria-expanded': 'false', 'aria-haspopup': 'false', 'autocapitalize': 'off', 'autocomplete': 'off', 'autocorrect': 'off', 'id': 'APjFqb', 'maxlength': '2048', 'name': 'q', 'role': 'combobox', 'rows': '1', 'spellcheck': 'false', 'jsaction': 'paste:puy29d', 'data-ved': '0ahUKEwiMhL-97JeNAxUEEEQIHU7oOMIQ39UDCAU'}, shadow_root=False, css_selector='html > body > div > div:nth-of-type(3) > form > div > div > div > div > div:nth-of-type(2) > textarea.gLFyf[title=\"Search\"][aria-label=\"Search\"][placeholder][autocomplete=\"off\"][id=\"APjFqb\"][name=\"q\"][role=\"combobox\"]', page_coordinates=None, viewport_coordinates=None, viewport_info=None)}, {'click_element_by_index': {'index': 8}, 'interacted_element': DOMHistoryElement(tag_name='textarea', xpath='html/body/div/div[3]/form/div/div/div/div/div[2]/textarea', highlight_index=8, entire_parent_branch_path=['div', 'div', 'form', 'div', 'div', 'div', 'div', 'div', 'textarea'], attributes={'class': 'gLFyf', 'aria-controls': 'Alh6id', 'aria-owns': 'Alh6id', 'autofocus': '', 'title': 'Search', 'value': '', 'aria-label': 'Search', 'placeholder': '', 'aria-autocomplete': 'both', 'aria-expanded': 'true', 'aria-haspopup': 'false', 'autocapitalize': 'off', 'autocomplete': 'off', 'autocorrect': 'off', 'id': 'APjFqb', 'maxlength': '2048', 'name': 'q', 'role': 'combobox', 'rows': '1', 'spellcheck': 'false', 'jsaction': 'paste:puy29d', 'data-ved': '0ahUKEwiMhL-97JeNAxUEEEQIHU7oOMIQ39UDCAU', 'style': '', 'aria-activedescendant': ''}, shadow_root=False, css_selector='html > body > div > div:nth-of-type(3) > form > div > div > div > div > div:nth-of-type(2) > textarea.gLFyf[title=\"Search\"][aria-label=\"Search\"][placeholder][autocomplete=\"off\"][id=\"APjFqb\"][name=\"q\"][role=\"combobox\"]', page_coordinates=None, viewport_coordinates=None, viewport_info=None)}, {'click_element_by_index': {'index': 15}, 'interacted_element': DOMHistoryElement(tag_name='input', xpath='html/body/div/div[3]/form/div/div/div[2]/div[4]/div[6]/center/input', highlight_index=15, entire_parent_branch_path=['div', 'div', 'form', 'div', 'div', 'div', 'div', 'div', 'center', 'input'], attributes={'class': 'gNO89b', 'value': 'Google Search', 'aria-label': 'Google Search', 'name': 'btnK', 'role': 'button', 'tabindex': '0', 'type': 'submit', 'data-ved': '0ahUKEwiMhL-97JeNAxUEEEQIHU7oOMIQ4dUDCA8', 'style': ''}, shadow_root=False, css_selector='html > body > div > div:nth-of-type(3) > form > div > div > div:nth-of-type(2) > div:nth-of-type(4) > div:nth-of-type(6) > center > input.gNO89b[aria-label=\"Google Search\"][name=\"btnK\"][role=\"button\"][type=\"submit\"]', page_coordinates=None, viewport_coordinates=None, viewport_info=None)}, {'done': {'text': 'The price comparison between GPT-4o and DeepSeek-V3 is as follows: GPT-4o charges $1.25 per million input cache hit tokens, $2.50 per million input cache miss tokens, and $10 per million output tokens. DeepSeek-V3 charges $0.07 per million input cache hit tokens, $0.27 per million input cache miss tokens, and $1.10 per million output tokens. This makes DeepSeek-V3 significantly more cost-effective compared to GPT-4o.', 'success': True}, 'interacted_element': None}])\n"
     ]
    }
   ],
   "source": [
    "#incorporate agent call\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from browser_use import Agent\n",
    "from pydantic import SecretStr\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# Initialize the model\n",
    "llm=ChatOllama(model=\"qwen3:14b\", num_ctx=32000)\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(\n",
    "        task=\"Compare the price of gpt-4o and DeepSeek-V3\",\n",
    "        llm=llm,\n",
    "        page_extraction_llm=llm\n",
    "    )\n",
    "    result = await agent.run()\n",
    "    print(result)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ollama building block only--more complez\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from browser_use import Agent\n",
    "from pydantic import SecretStr\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "llm=ChatOllama(model=\"qwen3\", num_ctx=32000)\n",
    "planner_llm = ChatOllama(model='qwen3')\n",
    "\n",
    "# Create agent with the model\n",
    "# Create agent with the model\n",
    "agent = Agent(\n",
    "    task='''research how the digital china program is seeking to advance china\n",
    "    AI capabilities. Use only info found at https://digitalchinawinsthefuture.com/''',\n",
    "    llm=llm,\n",
    "    planner_llm=planner_llm,           # Separate model for planning\n",
    "    use_vision_for_planner=False,      # Disable vision for planner\n",
    "    planner_interval=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scraps below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 31) (1222905217.py, line 31)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel='qwen3,        # Or 'llama3', 'mistral', etc.\u001b[39m\n                                                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 31)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import ChatOllama # Using Ollama\n",
    "\n",
    "# --- Ensure browser_use is installed or correctly on sys.path ---\n",
    "try:\n",
    "    from browser_use import Agent, Browser, BrowserConfig # Import Browser and Config\n",
    "    print(\"Successfully imported browser_use components.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing browser_use: {e}\")\n",
    "    print(\"Please ensure 'browser_use' is installed in your Jupyter kernel's environment.\")\n",
    "    print(\"You might need to run: pip install browser-use  (or similar, depending on the package name)\")\n",
    "    # Or ensure the path is correct if it's a local module\n",
    "    # cwd = os.getcwd()\n",
    "    # print(f\"Current working directory: {cwd}\")\n",
    "    # print(f\"Python path: {sys.path}\")\n",
    "    raise # Stop execution if import fails\n",
    "\n",
    "# Load environment variables if needed\n",
    "load_dotenv()\n",
    "print(\"Environment variables loaded (if .env file exists).\")\n",
    "\n",
    "# Initialize the model using Ollama\n",
    "# --- Make sure your Ollama service is running locally ---\n",
    "llm = None # Initialize llm to None\n",
    "try:\n",
    "    llm = ChatOllama(\n",
    "        model='qwen3,        # Or 'llama3', 'mistral', etc.\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    print(f\"Successfully initialized Ollama model: {llm.model}\")\n",
    "    # Optional: Quick test\n",
    "    # llm.invoke(\"test connection\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Ollama model: {e}\")\n",
    "    print(\"Please ensure the Ollama service is running and the model is available.\")\n",
    "    raise # Stop execution if LLM fails\n",
    "\n",
    "# --- Explicit Browser Configuration ---\n",
    "# Note: Playwright browsers might need to be installed ('playwright install' in terminal/cell)\n",
    "browser = None # Initialize browser to None\n",
    "try:\n",
    "    print(\"Configuring browser...\")\n",
    "    config = BrowserConfig(\n",
    "        headless=True,  # Run without a visible browser window\n",
    "        # user_agent=\"...\", # Optional\n",
    "        # viewport={\"width\": 1920, \"height\": 1080}, # Optional\n",
    "    )\n",
    "    print(\"Initializing browser...\")\n",
    "    # This step might download browser drivers on first run\n",
    "    browser = Browser(config=config)\n",
    "    print(\"Browser initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Browser: {e}\")\n",
    "    print(\"This might be due to Playwright browsers not being installed.\")\n",
    "    print(\"Try running '!playwright install' in a cell or 'playwright install' in your terminal.\")\n",
    "    raise # Stop execution if browser fails\n",
    "\n",
    "# Define the task for the agent\n",
    "current_year = 2025 # Based on user context\n",
    "future_date = f\"{current_year + 1}-05-01\" # Use next year for the search\n",
    "task = f'Go to kayak.com and find the cheapest flight from Zurich (ZRH) to San Francisco (SFO) departing on {future_date}'\n",
    "print(f\"Task defined: {task}\")\n",
    "\n",
    "# Initialize the Agent - *Pass the browser instance*\n",
    "print(\"Initializing Agent...\")\n",
    "if llm and browser:\n",
    "    agent = Agent(task=task, llm=llm, browser=browser) # Pass browser here\n",
    "    print(\"Agent initialized.\")\n",
    "else:\n",
    "    print(\"Cannot initialize Agent due to previous errors.\")\n",
    "    raise ValueError(\"LLM or Browser not initialized successfully.\")\n",
    "\n",
    "\n",
    "# Define the main asynchronous function\n",
    "async def main():\n",
    "    print(\"Running agent asynchronously...\")\n",
    "    result = None # Initialize result\n",
    "    try:\n",
    "        result = await agent.run()\n",
    "        print(\"Agent run completed.\")\n",
    "        # Process result\n",
    "        if result and hasattr(result, 'action_results'):\n",
    "            print(\"Processing actions...\")\n",
    "            final_content = []\n",
    "            for action in result.action_results():\n",
    "                print(f\"  Action: {action.action_type}, Status: {action.status}\")\n",
    "                if action.extracted_content:\n",
    "                    content_snippet = action.extracted_content[:200].replace('\\n', ' ') + ('...' if len(action.extracted_content) > 200 else '')\n",
    "                    print(f\"    Extracted: {content_snippet}\")\n",
    "                    final_content.append(action.extracted_content)\n",
    "            print(\"\\n--- Combined Extracted Content ---\")\n",
    "            print(\"\\n\\n\".join(final_content) if final_content else \"No content extracted.\")\n",
    "            print(\"--------------------------------\")\n",
    "\n",
    "        elif result:\n",
    "            print(f\"Agent Result (raw): {result}\")\n",
    "        else:\n",
    "            print(\"Agent did not return a result.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during agent execution: {e}\")\n",
    "        # You might want to re-raise the exception for debugging\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # raise\n",
    "    finally:\n",
    "        # Ensure the browser used by the agent is closed\n",
    "        # Since we passed the browser instance, we can close it directly\n",
    "        if browser and hasattr(browser, 'close'):\n",
    "            print(\"Attempting to close browser...\")\n",
    "            try:\n",
    "                await browser.close()\n",
    "                print(\"Browser closed.\")\n",
    "            except Exception as close_e:\n",
    "                print(f\"Error closing browser: {close_e}\")\n",
    "        else:\n",
    "            print(\"Browser instance not available for cleanup.\")\n",
    "\n",
    "# Run the main async function in Jupyter\n",
    "# No need for 'if __name__ == \"__main__\":' when running directly in a cell\n",
    "print(\"Starting async execution...\")\n",
    "try:\n",
    "    # In modern Jupyter/IPython, you might be able to just 'await main()'\n",
    "    # but asyncio.run() is generally safer for compatibility.\n",
    "    asyncio.run(main())\n",
    "    print(\"Async execution finished successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An critical error occurred running main: {e}\")\n",
    "    # Print traceback if error happens here\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    print(\"Execution block finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4337,
     "status": "ok",
     "timestamp": 1739346197587,
     "user": {
      "displayName": "Lukas F",
      "userId": "07341902451649282007"
     },
     "user_tz": 600
    },
    "id": "kyydyLGQlxpt",
    "outputId": "02345da6-fc65-46dd-ced5-77d91ed7db6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†º \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ß \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ã \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¥ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†¶ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†á \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†è \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†ô \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†π \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G‚†∏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?25l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[K\u001b[?25h\u001b[?2026l\u001b[2K\u001b[1G\u001b[?25h<think>\u001b[?25l\u001b[?25h\n",
      "\u001b[?25l\u001b[?25hOkay\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h so\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h user\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h asking\u001b[?25l\u001b[?25h for\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h capital\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h France\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Let\u001b[?25l\u001b[?25h me\u001b[?25l\u001b[?25h think\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h know\u001b[?25l\u001b[?25h\u001b[4D\u001b[K\n",
      "know that\u001b[?25l\u001b[?25h France\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h country\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h Europe\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h its\u001b[?25l\u001b[?25h capital\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h major\u001b[?25l\u001b[?25h city\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h\u001b[1D\u001b[K\n",
      "I remember\u001b[?25l\u001b[?25h from\u001b[?25l\u001b[?25h school\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h Paris\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h capital\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h But\u001b[?25l\u001b[?25h wait\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h should\u001b[?25l\u001b[?25h double\u001b[?25l\u001b[?25h\u001b[6D\u001b[K\n",
      "double-check\u001b[?25l\u001b[?25h to\u001b[?25l\u001b[?25h make\u001b[?25l\u001b[?25h sure\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h'm\u001b[?25l\u001b[?25h not\u001b[?25l\u001b[?25h confusing\u001b[?25l\u001b[?25h it\u001b[?25l\u001b[?25h with\u001b[?25l\u001b[?25h another\u001b[?25l\u001b[?25h country\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h For\u001b[?25l\u001b[?25h ex\u001b[2D\u001b[K\n",
      "example\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h Spain\u001b[?25l\u001b[?25h's\u001b[?25l\u001b[?25h capital\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h Madrid\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h Germany\u001b[?25l\u001b[?25h's\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h Berlin\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h No\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h France\u001b[?25l\u001b[?25h's\u001b[?25l\u001b[?25h i\u001b[1D\u001b[K\n",
      "is\u001b[?25l\u001b[?25h definitely\u001b[?25l\u001b[?25h Paris\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Let\u001b[?25l\u001b[?25h me\u001b[?25l\u001b[?25h confirm\u001b[?25l\u001b[?25h by\u001b[?25l\u001b[?25h recalling\u001b[?25l\u001b[?25h some\u001b[?25l\u001b[?25h landmarks\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h The\u001b[?25l\u001b[?25h E\u001b[?25l\u001b[?25hiff\u001b[?25l\u001b[?25hel\u001b[?25l\u001b[?25h\u001b[6D\u001b[K\n",
      "Eiffel Tower\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Lou\u001b[?25l\u001b[?25hvre\u001b[?25l\u001b[?25h Museum\u001b[?25l\u001b[?25h are\u001b[?25l\u001b[?25h in\u001b[?25l\u001b[?25h Paris\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Yeah\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h's\u001b[?25l\u001b[?25h right\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h So\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h\u001b[3D\u001b[K\n",
      "the answer\u001b[?25l\u001b[?25h should\u001b[?25l\u001b[?25h be\u001b[?25l\u001b[?25h Paris\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h don\u001b[?25l\u001b[?25h't\u001b[?25l\u001b[?25h think\u001b[?25l\u001b[?25h there\u001b[?25l\u001b[?25h's\u001b[?25l\u001b[?25h any\u001b[?25l\u001b[?25h other\u001b[?25l\u001b[?25h city\u001b[?25l\u001b[?25h that\u001b[?25l\u001b[?25h's\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h\u001b[3D\u001b[K\n",
      "the capital\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h France\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Maybe\u001b[?25l\u001b[?25h someone\u001b[?25l\u001b[?25h might\u001b[?25l\u001b[?25h think\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h Lyon\u001b[?25l\u001b[?25h or\u001b[?25l\u001b[?25h Marseille\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h but\u001b[?25l\u001b[?25h \u001b[K\n",
      "those\u001b[?25l\u001b[?25h are\u001b[?25l\u001b[?25h not\u001b[?25l\u001b[?25h capitals\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h So\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h'm\u001b[?25l\u001b[?25h confident\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h answer\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h Paris\u001b[?25l\u001b[?25h.\n",
      "\u001b[?25l\u001b[?25h</think>\u001b[?25l\u001b[?25h\n",
      "\n",
      "\u001b[?25l\u001b[?25hThe\u001b[?25l\u001b[?25h capital\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h France\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h **\u001b[?25l\u001b[?25hParis\u001b[?25l\u001b[?25h**\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h It\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h major\u001b[?25l\u001b[?25h global\u001b[?25l\u001b[?25h city\u001b[?25l\u001b[?25h known\u001b[?25l\u001b[?25h for\u001b[?25l\u001b[?25h lan\u001b[3D\u001b[K\n",
      "landmarks\u001b[?25l\u001b[?25h such\u001b[?25l\u001b[?25h as\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h E\u001b[?25l\u001b[?25hiff\u001b[?25l\u001b[?25hel\u001b[?25l\u001b[?25h Tower\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Lou\u001b[?25l\u001b[?25hvre\u001b[?25l\u001b[?25h Museum\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h Ch\u001b[?25l\u001b[?25hamps\u001b[?25l\u001b[?25h-\u001b[?25l\u001b[?25h√â\u001b[?25l\u001b[?25hlys\u001b[?25l\u001b[?25h√©\u001b[12D\u001b[K\n",
      "Champs-√âlys√©es\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Paris\u001b[?25l\u001b[?25h has\u001b[?25l\u001b[?25h been\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h political\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h cultural\u001b[?25l\u001b[?25h,\u001b[?25l\u001b[?25h and\u001b[?25l\u001b[?25h economic\u001b[?25l\u001b[?25h center\u001b[?25l\u001b[?25h\u001b[6D\u001b[K\n",
      "center of\u001b[?25l\u001b[?25h France\u001b[?25l\u001b[?25h since\u001b[?25l\u001b[?25h the\u001b[?25l\u001b[?25h \u001b[?25l\u001b[?25h1\u001b[?25l\u001b[?25h2\u001b[?25l\u001b[?25hth\u001b[?25l\u001b[?25h century\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
      "\n",
      "\u001b[?25l\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!ollama run qwen3:14b \"What is the capital of France?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmsJSFRsmCLa"
   },
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    task=\"your task\",\n",
    "    llm=llm,\n",
    "    controller=custom_controller,  # For custom tool calling\n",
    "    use_vision=True,              # Enable vision capabilities\n",
    "    save_conversation_path=\"logs/conversation.json\"  # Save chat logs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-WGcBluAK48"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEHd-XjUA84Q"
   },
   "outputs": [],
   "source": [
    "#use groq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from browser_use import Agent\n",
    "from browser_use.browser.browser import Browser\n",
    "from browser_use.browser.browser import BrowserConfig\n",
    "from browser_use.browser.context import BrowserContextConfig, BrowserContextWindowSize\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"XXXXX\"\n",
    "# Initialize Groq client\n",
    "#llm=ChatGroq(model='llama-3.3-70b-versatile', api_key=api_key)\n",
    "\n",
    "llm=ChatGroq(model='llama3-70b-8192', api_key=api_key)\n",
    "\n",
    "async def run_agent():\n",
    "    config = BrowserConfig(headless=True,\n",
    "                           disable_security=True)\n",
    "    browser = Browser(config)\n",
    "\n",
    "    agent = Agent(\n",
    "        task=\"Who is Lukas Filler?\",\n",
    "        llm=llm,\n",
    "        browser=browser,\n",
    "        generate_gif=False,\n",
    "        use_vision=False\n",
    ")\n",
    "    result = await agent.run()\n",
    "    print(\"Agent result:\", result)\n",
    "\n",
    "# Run agent asynchronously\n",
    "asyncio.run(run_agent())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "error",
     "timestamp": 1739379144695,
     "user": {
      "displayName": "Lukas F",
      "userId": "07341902451649282007"
     },
     "user_tz": 600
    },
    "id": "0w9Gr1BjEx5e",
    "outputId": "c2434746-4173-41a4-8bb0-6b3f69ffb976"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent result:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mresult\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Agent result:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMkQ/h7dZP10i1NLo6yL5zb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "browser-use",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
